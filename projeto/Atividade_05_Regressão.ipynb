{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier"
      ],
      "metadata": {
        "id": "8Q3vSt4iOZUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercício 1 - Dataset \"car_crashes\" do seaborn"
      ],
      "metadata": {
        "id": "AtGO5p4PPEs7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3zNAo4jbCKF"
      },
      "outputs": [],
      "source": [
        "## Exercício 1 - Dataset \"car_crashes\" do seaborn\n",
        "\n",
        "# 1) Carregar o dataset \"car_crashes\"do seaborn\n",
        "# 2) Dropar a coluna \"abbrev\"\n",
        "# 3) Separar o dataframe, deixando a coluna 'total' para o target (coluna objetivo - y) e o restante para o X\n",
        "# 4) Normalizar todo o X\n",
        "# 5) Separar os dados em treinamento e teste\n",
        "# 6) Treinar um modelo linear\n",
        "# 7) Treinar uma árvores de regressão\n",
        "# 8) Treinar um KNN para regressão\n",
        "# 9) Apresentar os resultados dos erros usando: MSE, MAE e RMSE para os 3 modelos\n",
        "\n",
        "dataset = sns.load_dataset('car_crashes')\n",
        "dataset = dataset.drop('abbrev', axis=1)\n",
        "\n",
        "y = dataset['total']\n",
        "X = dataset.drop('total', axis=1)\n",
        "\n",
        "dataset = X.values\n",
        "min_max_scaler = MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(dataset)\n",
        "X = pd.DataFrame(x_scaled)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "model_1 = LinearRegression()\n",
        "model_2 = DecisionTreeRegressor()\n",
        "model_3 = KNeighborsRegressor(n_neighbors=10, algorithm='brute', metric='euclidean')\n",
        "\n",
        "model_1 = model_1.fit(X_train, y_train)\n",
        "model_2 = model_2.fit(X_train, y_train)\n",
        "model_3 = model_3.fit(X_train, y_train)\n",
        "\n",
        "result_1 = model_1.predict(X_test)\n",
        "result_2 = model_2.predict(X_test)\n",
        "result_3 = model_3.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_1 = metrics.mean_squared_error(result_1, y_test)\n",
        "mae_1 = metrics.mean_absolute_error(result_1, y_test)\n",
        "rmse_1 = metrics.root_mean_squared_error(result_1, y_test)\n",
        "print('----- LinearRegression')\n",
        "print(f'MSE: {mse_1:.2f}')\n",
        "print(f'MAE: {mae_1:.2f}')\n",
        "print(f'RMSE: {rmse_1:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbd5J10kNBbr",
        "outputId": "0e483c60-6bd7-4326-a626-c7dfc984208e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- LinearRegression\n",
            "MSE: 0.81\n",
            "MAE: 0.73\n",
            "RMSE: 0.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_2 = metrics.mean_squared_error(result_2, y_test)\n",
        "mae_2 = metrics.mean_absolute_error(result_2, y_test)\n",
        "rmse_2 = metrics.root_mean_squared_error(result_2, y_test)\n",
        "print('----- DecisionTreeRegressor')\n",
        "print(f'MSE: {mse_2:.2f}')\n",
        "print(f'MAE: {mae_2:.2f}')\n",
        "print(f'RMSE: {rmse_2:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6bWr03jNDj8",
        "outputId": "8720c152-beb2-401b-82a4-7756212c911b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- DecisionTreeRegressor\n",
            "MSE: 5.19\n",
            "MAE: 2.01\n",
            "RMSE: 2.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_3 = metrics.mean_squared_error(result_3, y_test)\n",
        "mae_3 = metrics.mean_absolute_error(result_3, y_test)\n",
        "rmse_3 = metrics.root_mean_squared_error(result_3, y_test)\n",
        "print('----- KNeighborsRegressor')\n",
        "print(f'MSE: {mse_3:.2f}')\n",
        "print(f'MAE: {mae_3:.2f}')\n",
        "print(f'RMSE: {rmse_3:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZv2HNDMNNjJ",
        "outputId": "8b380b0a-344e-4b24-b7b7-d91564099622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- KNeighborsRegressor\n",
            "MSE: 8.25\n",
            "MAE: 2.13\n",
            "RMSE: 2.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercício 2 - Dataset Parkinsons (dataset com 2 classes)"
      ],
      "metadata": {
        "id": "ZGQnXHtgPKyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercício 2 - Dataset Parkinsons (dataset com 2 classes)\n",
        "\n",
        "# 1) Carregar o dataset \"parkinsons\" pela URL abaixo:\n",
        "\n",
        "# url = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/parkinsons.data\"\n",
        "\n",
        "# 2) Separar os dados y e X. A coluna y é a coluna 0 (zero)\n",
        "# 3) Normalizar todas as colunas de X (usando o mesmo código da questão anterior)\n",
        "# 4) Separar oa dados em treinamento e teste\n",
        "# 5) Treinar um modelo de regressão logística\n",
        "# 6) Treinar uma árvore de decisão\n",
        "# 7) Treinar um KNN para classificação\n",
        "# 8) Apresentar os resultados de acurácia em percentual\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/tmoura/machinelearning/master/parkinsons.data'\n",
        "\n",
        "dataset = pd.read_csv(url, header=None)\n",
        "columns = len(dataset.columns)\n",
        "\n",
        "y = dataset[0]\n",
        "X = dataset.iloc[:, 1:columns - 1]\n",
        "\n",
        "dataset = X.values\n",
        "min_max_scaler = MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(dataset)\n",
        "X = pd.DataFrame(x_scaled)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "model_1 = LogisticRegression()\n",
        "model_2 = DecisionTreeClassifier()\n",
        "model_3 = KNeighborsClassifier(n_neighbors=7, algorithm='brute', metric='euclidean')\n",
        "\n",
        "model_1 = model_1.fit(X_train, y_train)\n",
        "model_2 = model_2.fit(X_train, y_train)\n",
        "model_3 = model_3.fit(X_train, y_train)\n",
        "\n",
        "result_1 = model_1.predict(X_test)\n",
        "result_2 = model_2.predict(X_test)\n",
        "result_3 = model_3.predict(X_test)"
      ],
      "metadata": {
        "id": "NecXgZ5iytCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_1 = metrics.accuracy_score(result_1, y_test)\n",
        "acc_2 = metrics.accuracy_score(result_2, y_test)\n",
        "acc_3 = metrics.accuracy_score(result_3, y_test)\n",
        "\n",
        "print(f'----- LogistcRegression: {round(acc_1 * 100)}%')\n",
        "print(f'----- DecisionTreeRegressor: {round(acc_2 * 100)}%')\n",
        "print(f'----- KNeighborsRegressor: {round(acc_3 * 100)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMLklWBdNnSD",
        "outputId": "34d3bbd6-9c2f-4de3-8233-38f6f85fc07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- LogistcRegression: 90%\n",
            "----- DecisionTreeRegressor: 97%\n",
            "----- KNeighborsRegressor: 95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercício 3 - Dataset attention do seaborn"
      ],
      "metadata": {
        "id": "8dGC6F-6Og6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercício 3 - Dataset attention do seaborn\n",
        "\n",
        "# 1) Carregar o dataset \"attention\" do seaborn\n",
        "# 2) Fazer um LabelEncoder na coluna \"attention\"\n",
        "# 3) Separar o dataframe, deixando a coluna 'attention' para o target (coluna objetivo - y) e as colunas \"solutions\" e \"score\" para o X\n",
        "# 4) Normalizar todo o X usando o mesmo código da questão 1\n",
        "# 5) Separar os dados em treinamento e teste\n",
        "# 6) Treinar um modelo de regressão logística\n",
        "# 7) Treinar uma árvore de decisão\n",
        "# 8) Treinar um KNN para classificação\n",
        "# 9) Apresentar os resultados de acurárica em percentual\n",
        "\n",
        "dataset = sns.load_dataset('attention')\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "dataset['attention'] = label_encoder.fit_transform(dataset['attention'])\n",
        "dataset\n",
        "\n",
        "y = dataset['attention']\n",
        "X = dataset[['solutions', 'score']]\n",
        "\n",
        "dataset = X.values\n",
        "min_max_scaler = MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(dataset)\n",
        "X = pd.DataFrame(x_scaled)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "model_1 = LogisticRegression()\n",
        "model_2 = DecisionTreeClassifier()\n",
        "model_3 = KNeighborsClassifier(n_neighbors=7, algorithm='brute', metric='euclidean')\n",
        "\n",
        "model_1 = model_1.fit(X_train, y_train)\n",
        "model_2 = model_2.fit(X_train, y_train)\n",
        "model_3 = model_3.fit(X_train, y_train)\n",
        "\n",
        "result_1 = model_1.predict(X_test)\n",
        "result_2 = model_2.predict(X_test)\n",
        "result_3 = model_3.predict(X_test)"
      ],
      "metadata": {
        "id": "1PAlFH5Au-11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_1 = metrics.accuracy_score(result_1, y_test)\n",
        "acc_2 = metrics.accuracy_score(result_2, y_test)\n",
        "acc_3 = metrics.accuracy_score(result_3, y_test)\n",
        "\n",
        "print(f'----- LogistcRegression: {round(acc_1 * 100)}%')\n",
        "print(f'----- DecisionTreeRegressor: {round(acc_2 * 100)}%')\n",
        "print(f'----- KNeighborsRegressor: {round(acc_3 * 100)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEhdqgvX0LtL",
        "outputId": "c7a5cbb0-87ec-488a-d45a-661c5d221355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- LogistcRegression: 67%\n",
            "----- DecisionTreeRegressor: 58%\n",
            "----- KNeighborsRegressor: 58%\n"
          ]
        }
      ]
    }
  ]
}